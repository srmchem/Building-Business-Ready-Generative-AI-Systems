{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMj02DYCLeW29VXMWOuot2f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "751185796314473f9087cacb971c0933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1294c2b9211f4c8a8871ed0228cb82dd",
              "IPY_MODEL_691ff290898249b28dd9dd251b0c3691",
              "IPY_MODEL_c43241ee018d426aa8eb5177676664c8"
            ],
            "layout": "IPY_MODEL_9e160081fa00479c9b4a49fd706f2d71"
          }
        },
        "1294c2b9211f4c8a8871ed0228cb82dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8698950f901495189757a0285ca4f6a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_47d4f1c1740941959a30b2d7f38a50f5",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "691ff290898249b28dd9dd251b0c3691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6a4d6f8d854c75baafe041d2da72da",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f779a1a590414dd2afb28474449af582",
            "value": 4
          }
        },
        "c43241ee018d426aa8eb5177676664c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb0e7ca7ce84e73b3dd9cdb0f6c8a06",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9f1bd40c562040a8b9fe1d4d1905a794",
            "value": "‚Äá4/4‚Äá[00:13&lt;00:00,‚Äá‚Äá3.04s/it]"
          }
        },
        "9e160081fa00479c9b4a49fd706f2d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8698950f901495189757a0285ca4f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d4f1c1740941959a30b2d7f38a50f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f6a4d6f8d854c75baafe041d2da72da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f779a1a590414dd2afb28474449af582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eb0e7ca7ce84e73b3dd9cdb0f6c8a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1bd40c562040a8b9fe1d4d1905a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **üöÄ Getting Started with DeepSeek-R1-Distill-Llama-8B**  \n",
        "üìå **Copyright 2025, Denis Rothman**  \n",
        "\n",
        "---\n",
        "\n",
        "## **üöÄ Installing and running DeepSeek-R1-Distill-Llama-8B**  \n",
        "\n",
        "This notebook provides a **step-by-step guide** on how to **download and run DeepSeek-R1-Distill-Llama-8B** locally in **Google Drive**.  The version downloaded is an open-source distilled version of DeepSeek-R1 provided by  unsloth, an LLM accelerator,  on Hugging Face :https://unsloth.ai/\n",
        "\n",
        "If you don't want to use Google Drive, you can install the artefacts on a local machine, server or cloud server.\n",
        "\n",
        "### **üîπ How to Get Started**  \n",
        "1Ô∏è‚É£ **Install the model's artifacts** ‚Üí Set `install_deepseek=True` and run all cells.  \n",
        "2Ô∏è‚É£ **Restart the session** ‚Üí Disconnect and start a new session.  \n",
        "3Ô∏è‚É£ **Re-run the model** ‚Üí Set `install_deepseek=False` and run all cells again.  \n",
        "4Ô∏è‚É£ **Interact with the model** ‚Üí Use it in a prompt session!  \n",
        "\n",
        "‚ö†Ô∏è **System Requirements**  \n",
        "‚úÖ **GPU** ‚Äì Minimum **16GB** VRAM required.  \n",
        "‚úÖ **Google Drive Space** ‚Äì At least **20GB** free space.  \n",
        "üìå **Educational Use Only** ‚Äì For production, deploy artifacts on a **local or cloud server**.\n",
        "\n",
        "---\n",
        "\n",
        "## **üìñ Table of Contents**  \n",
        "\n",
        "### **1Ô∏è‚É£ Setting Up the DeepSeek Environment (Hugging Face)**  \n",
        "‚úÖ Checking GPU Activation  \n",
        "üìÇ Mounting Google Drive  \n",
        "‚öôÔ∏è Installing the Hugging Face Environment  \n",
        "üîÑ Ensuring `install_deepseek=True` for First Run  \n",
        "üìå Checking Transformer Version  \n",
        "\n",
        "### **2Ô∏è‚É£ Downloading DeepSeek-R1-Distill-Llama-8B**  \n",
        "üìÇ Verifying Download Path  \n",
        "\n",
        "### **3Ô∏è‚É£ Running a DeepSeek Session**  \n",
        "üîÑ Setting `install_deepseek=False` for Second Run  \n",
        "üìå Model Information  \n",
        "üí¨ Running an Interactive Prompt Session  \n",
        "\n",
        "---\n",
        "\n",
        "### **üí° Ready to Use DeepSeek?**  \n",
        "Follow the **installation steps**, ensure you have the required **hardware**, and launch your **interactive AI session** üöÄ"
      ],
      "metadata": {
        "id": "dB7uI-BJ94pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting up DeepSeek Hugging Face environment"
      ],
      "metadata": {
        "id": "mA0_omNcKCw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set install_deepseek to True to download and install R1 Distill Llama 8B locally\n",
        "# Set install_deepseek to False to run an R1 session\n",
        "install_deepseek=False"
      ],
      "metadata": {
        "id": "81qmq4cJ65_7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking GPU activation"
      ],
      "metadata": {
        "id": "2WX2FRUyvnmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lnpx8Ywvkqu",
        "outputId": "b9e81eba-7cdf-403b-da3b-b12b3de87ff1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar  5 08:11:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             46W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "87z54INBvyUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zJAvtheKuudm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4b223d-109a-459c-f0b5-b8585351275a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the cache directory in your Google Drive\n",
        "cache_dir = '/content/drive/MyDrive/genaisys/HuggingFaceCache'\n",
        "\n",
        "# Set environment variables to direct Hugging Face to use this cache directory\n",
        "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
        "#os.environ['HF_DATASETS_CACHE'] = os.path.join(cache_dir, 'datasets')"
      ],
      "metadata": {
        "id": "TzzNqXIRCSxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation Hugging Face environment\n",
        "\n",
        "Path in this notebook: drive/MyDrive/genaisys/\n"
      ],
      "metadata": {
        "id": "hk_OMj3Xv7H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip transformers==4.48.3"
      ],
      "metadata": {
        "id": "07XwZO2Bx1sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a793bd-3422-4456-e4a4-35837cb087c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"transformers==4.48.3\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.DeepSeek download\n",
        "\n"
      ],
      "metadata": {
        "id": "CMDClDdHJ1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import time\n",
        "if install_deepseek==True:\n",
        "   # Record the start time\n",
        "  start_time = time.time()\n",
        "\n",
        "  model_name = 'unsloth/DeepSeek-R1-Distill-Llama-8B'\n",
        "  # Load the tokenizer and model\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', torch_dtype='auto')\n",
        "\n",
        "    # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "FT1zO4ShzzON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b49839b-3482-49e3-abeb-6667e4652856"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==True:\n",
        " !ls -R /content/drive/MyDrive/genaisys/HuggingFaceCache"
      ],
      "metadata": {
        "id": "zz0hLeEhJTt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472429b8-467f-459b-d928-37e5273de51e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/genaisys/HuggingFaceCache:\n",
            "models--unsloth--DeepSeek-R1-Distill-Llama-8B  version.txt\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B:\n",
            "blobs  refs  snapshots\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/blobs:\n",
            "03910325923893259d090bfa92baa4088cd46573\n",
            "0ab389d23c02726e56c53379f99a420035974a33\n",
            "0c15378b8bf8af3ceaa5e7a81372996b5080fe2035fd304b491064f95b8625e2\n",
            "0fd8120f1c6acddc268ebc2583058efaf699a771\n",
            "13263c27b6e1c82a791559fc2fe27af0748060180c559220d45b93b5fffe239e\n",
            "21b8ca8f9ab09417c124d32ba5b9a59bcd417c4594e41a48d3e869a8a328a021\n",
            "49d6c171706a9c36a4ba5f358e9ce94c27557fa812da99aa5ef0961fcd35de3f\n",
            "846e0e5df0c5f053a21f9390ceec3eabc52d06b3\n",
            "afcf8b83f782748e77f548ee46a21ced225f3431\n",
            "d91915040cfac999d8c55f4b5bc6e67367c065e3a7a4e4b9438ce1f256addd86\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/refs:\n",
            "main\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots:\n",
            "71f34f954141d22ccdad72a2e3927dddf702c9de\n",
            "\n",
            "/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de:\n",
            "config.json\t\t\t  model-00003-of-00004.safetensors  tokenizer_config.json\n",
            "generation_config.json\t\t  model-00004-of-00004.safetensors  tokenizer.json\n",
            "model-00001-of-00004.safetensors  model.safetensors.index.json\n",
            "model-00002-of-00004.safetensors  special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.DeepSeek-R1-Distill-Llama-8B session"
      ],
      "metadata": {
        "id": "mPFjy90U2gcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "zMyxVpqI4tdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "if install_deepseek==False:\n",
        "  # Define the path to the model directory\n",
        "  model_path = '/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de'\n",
        "\n",
        "  # Record the start time\n",
        "  start_time = time.time()\n",
        "  # Load the tokenizer and model from the specified path\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype='auto', local_files_only=True)\n",
        "\n",
        "  # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "uyWIUDSt3_2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "751185796314473f9087cacb971c0933",
            "1294c2b9211f4c8a8871ed0228cb82dd",
            "691ff290898249b28dd9dd251b0c3691",
            "c43241ee018d426aa8eb5177676664c8",
            "9e160081fa00479c9b4a49fd706f2d71",
            "b8698950f901495189757a0285ca4f6a",
            "47d4f1c1740941959a30b2d7f38a50f5",
            "5f6a4d6f8d854c75baafe041d2da72da",
            "f779a1a590414dd2afb28474449af582",
            "4eb0e7ca7ce84e73b3dd9cdb0f6c8a06",
            "9f1bd40c562040a8b9fe1d4d1905a794"
          ]
        },
        "outputId": "17ba1cce-893e-42fa-bbff-fa48683df56e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "751185796314473f9087cacb971c0933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load the model: 14.71 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==False:\n",
        "  print(model.config)"
      ],
      "metadata": {
        "id": "jSgiBU2m8rJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a92382-85fc-4863-9e2d-0fdfc676204b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/genaisys/HuggingFaceCache/models--unsloth--DeepSeek-R1-Distill-Llama-8B/snapshots/71f34f954141d22ccdad72a2e3927dddf702c9de\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pad_token_id\": 128004,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 8.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"unsloth_fixed\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt"
      ],
      "metadata": {
        "id": "QTSNYBCb4vtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if install_deepseek==False:\n",
        "  prompt=\"\"\"\n",
        "  Explain how a product designer could transformer customer requirements for a traveling bag into a production plan.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "t99pgv0IQ30m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if install_deepseek==False:\n",
        "  # Record the start time\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  # Tokenize the input\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
        "\n",
        "  # Generate output with enhanced anti-repetition settings\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=1200,\n",
        "    repetition_penalty=1.5,             # Increase penalty to 1.5 or higher\n",
        "    no_repeat_ngram_size=3,             # Prevent repeating n-grams of size 3\n",
        "    temperature=0.6,                    # Reduce randomness slightly\n",
        "    top_p=0.9,                          # Nucleus sampling for diversity\n",
        "    top_k=50                            # Limits token selection to top-k probable tokens\n",
        "  )\n",
        "\n",
        "  # Decode and display the output\n",
        "  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  # Record the end time\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate the elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  print(f\"Time taken to load the model: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "  #print(generated_text)"
      ],
      "metadata": {
        "id": "Qt9GTrB34r2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe0c6af-7be4-4976-c757-00a9b270d0f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to load the model: 48.78 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "if install_deepseek==False:\n",
        "  # Assuming 'generated_text' contains the text you want to format\n",
        "  wrapped_text = textwrap.fill(generated_text, width=80)  # Adjust 'width' as needed\n",
        "\n",
        "  print(wrapped_text)\n"
      ],
      "metadata": {
        "id": "p4QX8niIK6Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2c5dfa-42c1-44eb-e244-ef00f56fce9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Explain how a product designer could transformer customer requirements for a\n",
            "traveling bag into a production plan.       The process involves understanding\n",
            "the user's needs, defining specifications through collaboration with\n",
            "manufacturers and suppliers to ensure quality standards are met. Finally,\n",
            "creating detailed blueprints that guide manufacturing.  Okay, so I need to\n",
            "explain step-by-step how aproduct designer transformscustomer\n",
            "requirementstoaproductionplanforatripplingbag.Let me think aboutthisprocessand\n",
            "break it down in my mind first.I guess starting fromthebeginningwhen someone\n",
            "wantsto createa newtravelingË¢ãÔºåthey must talktostheÂÆ¢Êà∑ÊàñËÄÖÁî®Êà∑‰∫ÜËß£‰ªñ‰ª¨ÁöÑÂÖ∑‰ΩìÈúÄÊ±Ç„ÄÇÈÇ£‰πàÔºåËøô‰∏™ËøáÁ®ãÊòØÊÄéÊ†∑ÁöÑÂë¢Ôºü\n",
            "È¶ñÂÖàÔºåÊàëÂ∫îËØ•ËÄÉËôë‰∏éÈ°æÂÆ¢ËøõË°åÊ≤üÈÄöÂíåÁêÜËß£ÂÖ∂ÁúüÂÆûÈúÄË¶Å„ÄÇËøôÂèØËÉΩÂåÖÊã¨ËÆ®ËÆ∫ËØ•ËÉåÂåÖÂ∞ÜÁî®‰∫é‰ΩïÁßçÂú∫ÂêàÔºåÊòØËΩª‰æø„ÄÅËÄêÁî®ËøòÊòØÊúâÂÖ∂‰ªñÁâπÊÄß„ÄÇ\n",
            "Êé•‰∏ãÊù•ÔºåÊàñËÆ∏‰ºöÊî∂ÈõÜÊâÄÊúâÂøÖË¶Å‰ø°ÊÅØÔºåÂ¶ÇÂ∞∫ÂØ∏Ë¶ÅÊ±ÇÔºàÂÆΩÂ∫¶„ÄÅÈ´òÂ∫¶Ôºâ„ÄÅÈáçÈáèÈôêÂà∂Ôºå‰ª•ÂèäÊùêÊñôÂÅèÂ•Ω„ÄÇÊ≠§Â§ñÔºåËøòË¶ÅÂÖ≥Ê≥®ÂäüËÉΩÊñπÈù¢ÁöÑÈóÆÈ¢òÔºåÊØîÂ¶ÇÊòØÂê¶Â∏¶ÊãâÈìæÔºåÊúâÊ≤°ÊúâÂÜÖÈÉ® pockets\n",
            "ÊàñËÄÖÂ§öÊù°ËÇ©ÁªëÁ≠âËÆæËÆ°ÂÖÉÁ¥†„ÄÇ  ÁÑ∂ÂêéÔºåÂ∞ÜËøô‰∫õÊï¥ÁêÜÊàê‰∏Ä‰∏™ËØ¶ÁªÜ‰∏îÊ∏ÖÊô∞ÁöÑ‰∫ßÂìÅËßÑÊ†ºËØ¥Êòé‰π¶Ôºå‰ª•‰æõÂà∂ÈÄ†ÂïÜÂèÇËÄÉ„ÄÇÂú®Ëøô‰∏™Èò∂ÊÆµÔºå‰πüÂæàÈáçË¶ÅÁöÑÊòØÁ°Æ‰øùÊØè‰∏ÄÈ°πÈÉΩË¢´ÂáÜÁ°ÆÂÆö‰πâÔºåÊ≤°ÊúâÈÅóÊºèÊàñËØØËß£ÁöÑÂú∞\n",
            "Êñπ„ÄÇÂ¶ÇÊûúÂá∫Áé∞‰∏çÊ∏ÖÊ•ö‰πãÂ§ÑÔºåÊúÄÂ•ΩÁöÑÊñπÊ≥ïÂ∞±ÊòØÂõûÂéªÂêëÂÆ¢Êà∑ÊæÑÊ∏ÖÔºåÊâÄ‰ª•Ëøô‰πüÊòØÂÖ≥ÈîÆÁöÑ‰∏ÄÊ≠•„ÄÇ  ‰πãÂêéÔºåÂ∞±ÂèØ‰ª•ÂºÄÂßãÂú®ËÑëÊµ∑‰∏≠ÊûÑÊÄùÂ¶Ç‰ΩïÊääËøô‰∫õÂáΩÊï∞ËΩ¨Âåñ‰∏∫Áâ©ÁêÜÂΩ¢ÊÄÅ‰∫Ü„ÄÇ‰∏Ä‰Ωç‰ºòÁßÄÁöÑÊâãÂ∑•Ëâ∫ÂìÅÂ∫ó\n",
            "‰∏ªÈÄöÂ∏∏Êúâ‰∏ÄÂ•óÂ∑•ÂÖ∑ÁÆ±ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁßçËçâÂõæÁ∫∏Âº†Ôºå‰∏çÂêåÁ±ªÂûãÁ¨îËÆ∞Êú¨‰ª•ÂèäÊ®°ÊùøÊù•Â∏ÆÂä©ËÆ∞ÂΩïÊÉ≥Ê≥ï„ÄÇÊàëËßâÂæóËøôÈáåÊúÄÈöæËÉΩÂèØË¥µÁöÑ‰∫ãÊÉÖÔºåÂ∞±ÊòØËÉΩÂ§üÁ≤æÂáÜÂú∞ÊçïÊçâÂà∞ÈÇ£‰∫õÂ∞èËÄåËá≥ÂÖ≥Á¥ßÂØÜÁöÑÁÇπÔºåËÆ©Êï¥‰∏™ÊóÖË£Ö\n",
            "ÁúãËµ∑Êù•Êó¢ÁæéËßÇÂèàÂÆûÁî®ÁöÑÁªìÊûÑÂÆâÊéí„ÄÇ  ÂΩì‰Ω†ÂØπÂ§ßËá¥Ê¶ÇÂøµÊª°ÊÑèÂêéÔºå‰Ω†Â∞±ÂæóËÆ©Áîü‰∫ßÈÉ®Èó®Áü•ÈÅì‰Ω†ÁöÑËÆ°ÂàíÔºåÂπ∂Êèê‰æõË∂≥Â§üÁöÑÊäÄÊúØËµÑÊñôÁªô‰æõÂ∫îÂïÜ‰ª¨ÂÆ°ÈòÖÂπ∂ÂáÜÂ§áÊäïÂÖ•Áîü‰∫ß„ÄÇ‰ΩÜ‰∏∫‰∫ÜÈÅøÂÖç‰ªª‰ΩïÈóÆÈ¢òÂèëÁîüÔºå\n",
            "‰∏ÄÂÆöÊòØÂú®Ëøô‰∏ÄÁéØËäÇÂÅöÂÖÖÂàÜÁöÑ‰∫ãÂâçÊ†∏Êü•Â∑•‰ΩúÔºåÁúãÂà∞‰∫ÜÂêóÔºüÊØîÊñπËØ¥ÔºåÂ¶ÇÊûúÊüê‰∫õÈÉ®‰ª∂Êó†Ê≥ïÊåâÊó∂Ëé∑ÂæóÔºåÈÇ£‰πàÂøÖÈ°ªÊèêÊó©ÂØªÊâæÊõø‰ª£ÊñπÊ°àÔºõÂ¶ÇÊûúÈ¢úËâ≤ÂçèË∞É‰∏äÂ≠òÂú®Âõ∞Êâ∞ÔºåÂèØ‰ª•È¢ÑËßÅ‰∏çÂêåÁöÑÊâπÊ¨°Èó¥ÈöîÊó∂Èó¥‰ª•\n",
            "ËææÂà∞ÊúÄ‰Ω≥ÊïàÊûú‚Ä¶‚Ä¶  ÊúÄÂêéÔºåÂΩì‰∏ÄÂàáÂà∂‰ΩúÂÆåÊØïÔºåÂèàÂõ†‰∏∫Ë¥®ÈáèÊéßÂà∂ÈùûÂ∏∏‰∏•Ë∞®ÔºåÊØè‰∏ÄÊ≠•È™§ÈÉΩ‰ºöÁªèËøáÊ£ÄÊü•Ôºå‰ªéÂéüÊñôÈááË¥≠ÂÜçÊ£ÄÈ™åÈõ∂ÈÖçÔºåÁÑ∂ÂêéÁªÑË£ÖÂÆåÊàêÂêéÁöÑÂÖ®Èù¢Ê£ÄÊµã„ÄÇËÄåÂè™ÊúâÁªèÂèóËøáËøôÊ†∑Á≥ªÁªüÊÄßÁöÑ\n",
            "ÂÆ°Ê†∏Á®ãÂ∫èÊâçËÉΩ‰øùËØÅÂá∫ÂéÇÂâçÁöÑ100%ÂêàÊ†ºÁéáÔºå‰ΩøÊ∂àË¥πËÄÖÁöÑ‰ΩøÁî®‰ΩìÈ™åÊõ¥Âä†È°∫ÁïÖÊÑâÂø´Âì¶ÔºÅ  ÊÄªÁªì‰∏Ä‰∏ãÂêßÔºö‰ªéÊúÄÂàùÁöÑ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÂ∞èÁõÆÊ†áÈÄêÊ∏êÂ±ïÂºÄÔºå‰ΩÜÂç¥‰∏çÂèØÂøΩËßÜÂÖ∂‰∏≠Êó†Êï∞ÈúÄÊ≥®ÊÑè‰∫ãÈ°πÔºåÂè™‰æù\n",
            "Èù†ÁªèÈ™åÊòØ‰∏çË°åÂï¶ÔºÅËøòÁúüÊòØÊå∫Â§çÊùÇÁöÑÂòõÔºåË¶ÅÂÖºÈ°æÂàõÈÄ†Âäõ‰πü‰∏çËÉΩÂ∞ëÔºåËÄåÊâßË°å‰∏äÁöÑÂêÑÁ±ªËÄÉÈáèÊõ¥ÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ‰∏çËøáÂè™Ë¶ÅÊåâÁÖßËøôÊ†∑ÁöÑÊµÅÁ®ãÊÖ¢ÊÖ¢Êé®ËøõÁöÑËØùÔºåËØ¥‰∏çÂÆöÁúüÁöÑÂèØ‰ª•ÊàêÂäüÊâìÈÄ†ÈÇ£Ê¨æ‰ª§‰∫∫ÂñúÁà±ÁöÑ\n",
            "Âú∞ÈÅìÊóÖË°åÁî®ÂìÅÔºÅ </think>  **Step-by-Step Explanation:**  1. **Understanding Customer\n",
            "Requirements**     - Engage directly with customers or users via surveys,\n",
            "interviews, or focus groups to gather insights on their specific travel luggage\n",
            "demands such as size (width, height), weight capacity, material preferences,\n",
            "intended use case scenarios like business vs leisure travel, durability\n",
            "expectations, design features desired including zippers, compartments, handles,\n",
            "etc., color schemes if any preference is indicated by them.  2. **Defining\n",
            "Product Specifications**     Once all necessary information has been collected:\n",
            "3. Collaborate closely with manufacturers/suppliers to confirm feasibility of\n",
            "each feature based on available materials technology and processes; discuss\n",
            "potential challenges early on ensuring alignment between client vision &\n",
            "manufacturable designs without compromising functionality; 4. Create\n",
            "comprehensive technical drawings/blueprint using CAD software tools highlighting\n",
            "every critical dimension detail placement structure allowing precise replication\n",
            "during massproductionÔºõ 5. Establish strict QC criteria at various\n",
            "stages‚Äîrawmaterial inspection component assembly final integration‚Äîto maintain\n",
            "consistency throughout the entire lifecycle;  6.Present finalized plans to\n",
            "stakeholders obtaining approval before moving forward ensures smooth transition\n",
            "towards actual manufacturing phase.  7.Managing Production Process EfficientlyÔºö\n",
            "8.Monitor progress regularly reviewing samples when feasible catching issues\n",
            "promptly addressing deviations quickly preventing costly reworks downstream\n",
            "which can significantly impact timelines budgets while maintaining high-quality\n",
            "standardsthus maximizing productivity efficiency within supply chain network.\n",
            "9.Implementation Quality Control Checks Throughout Each Stage Ensuring Every\n",
            "Component Meets Precise Specifications Performed By Skilled Inspectors To\n",
            "Maintain Consistency And Reliability In Final Products Reducing The Risk Of\n",
            "Returns Or Complaints Post-Launch Due To Substandard Materials/Workmanship.\n",
            "10.Documentation archiving All Aspects From Design Changes Made During\n",
            "Manufacturing Through Testing Data Results Essential For Future Enhancements\n",
            "Iterations Improvements While Keeping Detailed Records Facilitating Compliance\n",
            "Audits Traceability If Required Down Line Should They Occur SuchAs Recall\n",
            "Processes Etcetera.  11.Final Review Approval Before Release Sign Off On\n",
            "Finished Goods Only After Full Satisfaction With Outcome Confirm That It Exceeds\n",
            "Expectations Delivering Unparalleled User Experience ReflectiveOf Thorough\n",
            "Planning Execution Precision Craftsmanship Attention Detail Orientation\n",
            "CommitmentToQualityThatSetsThisProduct ApartInMarketplaceCompetitionOutshinesRiv\n",
            "alsWithSuperiorDesignFunctionalityAndDurabilityEnsuresLongTermCustomerSatisfacti\n",
            "onBuildingTrustBrandLoyaltyandin turnDrivingRepeatBusinessGrowthForCompany\n"
          ]
        }
      ]
    }
  ]
}