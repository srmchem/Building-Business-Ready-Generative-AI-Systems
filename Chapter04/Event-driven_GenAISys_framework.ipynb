{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6NpoT6UaY3ixtYs7isOJF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "caa50029d4744f40a8d4244fd459cc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_2a2f78f5d1f34df78ce50eaef72c6fca"
          }
        },
        "e2c87436b0654dde96b28d2905b0e0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "User01",
              "User02",
              "User03"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "User:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_765ed4e2c99249dba075978e63f47612",
            "style": "IPY_MODEL_de0bbf6143cd45c5bd8f5baec3ef0885"
          }
        },
        "c5a592f0edde425aa3b0c415e763deff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4c789031c7f84438ba6b6478c45c30f7",
            "placeholder": "Type your message here or type 'exit' or 'quit' to end the conversation.",
            "style": "IPY_MODEL_2516b112d6794da19870a2358b7118ca",
            "value": ""
          }
        },
        "cde4d28a53cc496a915041411142d6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Agent",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_349df2853f0148ca97e1f3682ea8d7cc",
            "style": "IPY_MODEL_660dab06c899408d8372a6f27c4febe8",
            "value": true
          }
        },
        "2a2f78f5d1f34df78ce50eaef72c6fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "flex-start",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "765ed4e2c99249dba075978e63f47612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "de0bbf6143cd45c5bd8f5baec3ef0885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c789031c7f84438ba6b6478c45c30f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2516b112d6794da19870a2358b7118ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "349df2853f0148ca97e1f3682ea8d7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "660dab06c899408d8372a6f27c4febe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1528c9f73131416195e55f25a73e229a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_f2ca3d1f42ea4a07bb6d40290caac17b"
          }
        },
        "f2ca3d1f42ea4a07bb6d40290caac17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5c2aa6533b4fcb80a57c525233adca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_0077bf97b10941c2a565f48a5beeb653"
          }
        },
        "0077bf97b10941c2a565f48a5beeb653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac47bd5e23a340f3a777ee48a02d3c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_074b1e3e88744be484a2bb4da250284c"
          }
        },
        "074b1e3e88744be484a2bb4da250284c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbae20c3402344fc93f4c2b75a86721d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_1ba51e1e9a074d0e89fcc1afdbe2387d"
          }
        },
        "1ba51e1e9a074d0e89fcc1afdbe2387d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed262e19645c41ebb4626edde59ad8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c87436b0654dde96b28d2905b0e0bf",
              "IPY_MODEL_c5a592f0edde425aa3b0c415e763deff",
              "IPY_MODEL_cde4d28a53cc496a915041411142d6da"
            ],
            "layout": "IPY_MODEL_ce086e365f31482aaac7e08089e6b041"
          }
        },
        "ce086e365f31482aaac7e08089e6b041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building an Event-driven GenAISys Framework\n",
        "\n",
        "copyright 2025, Denis Rothman\n",
        "\n",
        "As Generative AI spreads through hundreds of activities worldwide, the need for custom business-driven ChatGPT-like Generative AI Systems(GenAISys) is increasing.\n",
        "\n",
        "This notebook introduces a framework for a custom GenAISys for a business. The features take the system beyond public platforms into the real world of business constraints. As such, the framework includes:\n",
        "\n",
        "*  Multi-user dialogs in an interface between users with or without a GPT-4o GenAI agent.\n",
        "*  Multi-user dialogs with a GPT-4o GenAI agent\n",
        "*  Interactions with a Pinecone vector store that contains a repository of instructions for the GenAI that will be triggered in real-time\n",
        "* Interactions with a Pinecone vector store to retrieve episodic memories from a business. In this case, stored messages from a CTO that only the organization can know about.\n",
        "*  Interactions with the users without a GenAI being involved.\n",
        "*  An automated conversation log function that can also be leveraged to automatically generate the summary and action plan of an online multi-user meeting with a GenAI as a participant.\n",
        "\n",
        "**Notebook summary**\n",
        "\n",
        "1. Installing OpenAI and customer OpenAI GPT-4o calls.\n",
        "2. Installing Pinecone and connecting to the Pinecone Index\n",
        "3. Pinecone vector store querying functions\n",
        "4. A conversational agent\n",
        "5. A multi-user interface with the AI agent as a participant.\n",
        "6. Loading and displaying the conversation when it is over\n",
        "7. Summarizing and displaying the summary of the meeting.\n",
        "\n",
        "\n",
        "**Note**: *This notebook is for educational purposes only. It is not designed to be deployed into production.\n",
        "The notebook implements an educational dialog to verify the functions developed in the previous chapters and integrated in the multi-user interface of this notebook*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rA2_SNjzA4Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment"
      ],
      "metadata": {
        "id": "vub82Rjxa17a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File downloading script\n",
        "\n",
        "grequests contains a script to download files from the repository"
      ],
      "metadata": {
        "id": "S8_G2ePO11rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Private repository notes\n",
        "#1.This line will be deleted when the repository is made public and the following line will be uncommented\n",
        "#2.The private token will also be removed from grequests.py in the commmons directory of the repository\n",
        "!curl -L -H \"Authorization: Bearer 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\" https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4_26Hfdx2kX",
        "outputId": "ac1a9f1b-e6aa-411e-f754-d6db21ba3cb1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1008  100  1008    0     0   1620      0 --:--:-- --:--:-- --:--:--  1623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -L https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/commons/grequests.py --output grequests.py"
      ],
      "metadata": {
        "id": "vzkCTNNChWAJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "jmmBBZ7oa17b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from grequests import download\n",
        "download(\"commons\",\"requirements01.py\")\n",
        "download(\"commons\",\"openai_setup.py\")\n",
        "download(\"commons\",\"openai_api.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfb27ad-bb29-40a8-8149-78794612042d",
        "id": "G_PuE5rjhWAK"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements01.py' successfully.\n",
            "Downloaded 'openai_setup.py' successfully.\n",
            "Downloaded 'openai_api.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing OpenAI"
      ],
      "metadata": {
        "id": "9kNLfjTfAnFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7i8j5vnpatH",
        "outputId": "3d65757b-18cf-4360-f6fb-3adc701bb3dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'openai'...\n",
            "Installing 'openai' version 1.57.1...\n",
            "'openai' version 1.57.1 is installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing the OpenAI API key\n",
        "\n"
      ],
      "metadata": {
        "id": "O03SZzGGAreV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_secrets=True #activates Google secrets in Google Colab\n",
        "if google_secrets==True:\n",
        "  import openai_setup\n",
        "  openai_setup.initialize_openai_api()"
      ],
      "metadata": {
        "id": "pDn09vPbAXPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0c2d32-82d4-4d93-d4e4-9df11e4658f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the API_KEY\n",
        "  import os\n",
        "  #API_KEY=[YOUR API_KEY]\n",
        "  #os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "  #openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "C3398f_cetsD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NL93eSL-mLi"
      },
      "source": [
        "#### Importing the API call function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function from the custom OpenAI API file\n",
        "import openai_api\n",
        "from openai_api import make_openai_api_call"
      ],
      "metadata": {
        "id": "0lMhv09G0kzr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGI1D8FVrT6"
      },
      "source": [
        "## Installing Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"requirements02.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ufJsT54EHe",
        "outputId": "764372bc-1022-4651-ea2d-102e8063e5ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'requirements02.py' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z2abuU9OkVFL",
        "outputId": "7d5de786-ade1-4386-aef4-247ca72ed25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling 'pinecone-client'...\n",
            "Installing 'pinecone-client' version 5.0.1...\n"
          ]
        }
      ],
      "source": [
        "# Run the setup script to install and import dependencies\n",
        "%run requirements02"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the Pinecone API key"
      ],
      "metadata": {
        "id": "tum9Jd1odcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"commons\",\"pinecone_setup.py\")"
      ],
      "metadata": {
        "id": "2eIyjdd25LjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==True:\n",
        "  import pinecone_setup\n",
        "  pinecone_setup.initialize_pinecone_api()"
      ],
      "metadata": {
        "id": "0zPS_mgsdXKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if google_secrets==False: # Uncomment the code and choose any method you wish to initialize the Pinecone API key\n",
        "  import os\n",
        "  #PINECONE_API_KEY=[YOUR PINECONE_API_KEY]\n",
        "  #os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "  #openai.api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  #print(\"OpenAI API key initialized successfully.\")"
      ],
      "metadata": {
        "id": "D-dJTlEn_FZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswfiN5Z1OvT"
      },
      "source": [
        "##  The Pinecone index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# Retrieve the API key from environment variables\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment!\")\n",
        "\n",
        "# Initialize the Pinecone client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "cKCvBbZPTIjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P---PNLpXeQs"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "index_name = 'genai-v1'\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7AYljM0gq1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pinecone\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimension of the embedding model\n",
        "        metric='cosine',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Querying functions"
      ],
      "metadata": {
        "id": "9iIIeZB7RUDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(query_results):\n",
        "  for match in query_results['matches']:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n",
        "    if 'metadata' in match and 'text' in match['metadata']:\n",
        "        text=match['metadata']['text']\n",
        "        #print(f\"Text: {match['metadata']['text']}\")\n",
        "        target_id = query_results['matches'][0]['id']  # Get the ID from the first match\n",
        "                #print(f\"Target ID: {target_id}\")\n",
        "    else:\n",
        "        print(\"No metadata available.\")\n",
        "  return text, target_id\n"
      ],
      "metadata": {
        "id": "NS2HWdO76iQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT6wytGz5hTS"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "client = openai.OpenAI()\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "def get_embedding(text, model=embedding_model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    response = client.embeddings.create(input=[text], model=model)\n",
        "    embedding = response.data[0].embedding\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_results(query_text, namespace):\n",
        "    # Generate the query vector from the query text\n",
        "    query_vector = get_embedding(query_text)  # Replace with your method to generate embeddings\n",
        "\n",
        "    # Perform the query\n",
        "    query_results = index.query(\n",
        "        vector=query_vector,\n",
        "        namespace=namespace,\n",
        "        top_k=1,  # Adjust as needed\n",
        "        include_metadata=True\n",
        "    )\n",
        "    # Return the results\n",
        "    return query_results"
      ],
      "metadata": {
        "id": "_FxS2Q0nnZAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_vector_store(query_text, namespace):\n",
        "    print(\"Querying vector store...\")\n",
        "\n",
        "    # Retrieve query results\n",
        "    query_results = get_query_results(query_text, namespace)\n",
        "\n",
        "    # Process and display the results\n",
        "    print(\"Processed query results:\")\n",
        "    text, target_id = display_results(query_results)\n",
        "\n",
        "    return text, target_id"
      ],
      "metadata": {
        "id": "-k5GxQGZSjlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversational agent"
      ],
      "metadata": {
        "id": "VesAR25Ywxcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI()\n",
        "user_memory=True # True=User messages are memorized False=User messages are not memorized\n",
        "def chat_with_gpt(messages, user_message):\n",
        "    try:\n",
        "      namespace=\"\"\n",
        "      if \"Pinecone\" in user_message or \"RAG\" in user_message:\n",
        "         # Determine the keyword\n",
        "        if \"Pinecone\" in user_message:\n",
        "            namespace=\"genaisys\"\n",
        "        elif \"RAG\" in user_message:\n",
        "            namespace=\"data01\"\n",
        "        print(namespace)\n",
        "        #define query text\n",
        "        query_text=user_message\n",
        "        # Retrieve query results\n",
        "        query_results = get_query_results(query_text, namespace)\n",
        "        # Process and display the results\n",
        "        print(\"Processed query results:\")\n",
        "        qtext, target_id = display_results(query_results)\n",
        "        print(qtext)\n",
        "        #run task\n",
        "        sc_input=qtext + \" \" + user_message\n",
        "        mrole = \"system\"\n",
        "        mcontent = \"You are an assistant who executes the tasks you are asked to do.\"\n",
        "        user_role = \"user\"\n",
        "        task_response = openai_api.make_openai_api_call(sc_input,mrole,mcontent,user_role)\n",
        "        print(task_response)\n",
        "        aug_output=namespace + \":\" +task_response\n",
        "      else:\n",
        "        if user_memory:\n",
        "                # Extract ALL user messages from the conversation history\n",
        "                user_messages_content = [\n",
        "                    msg[\"content\"] for msg in messages\n",
        "                    if msg[\"role\"] == \"user\" and \"content\" in msg\n",
        "                ]\n",
        "\n",
        "                # Combine all extracted user messages into a single string\n",
        "                combined_user_messages = \" \".join(user_messages_content)\n",
        "\n",
        "                # Add the current user_message to the combined text\n",
        "                umessage = f\"{combined_user_messages} {user_message}\"\n",
        "        else:\n",
        "                umessage = user_message\n",
        "        mrole = \"system\"\n",
        "        mcontent = \"You are an assistant who executes the tasks you are asked to do.\"\n",
        "        user_role = \"user\"\n",
        "        task_response = openai_api.make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
        "        aug_output=task_response\n",
        "\n",
        "      # Return the augmented output\n",
        "      return aug_output\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return the error message in case of an exception\n",
        "        return f\"An error occurred: {str(e)}\""
      ],
      "metadata": {
        "id": "PEz84qfqs-0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GenAISys IPYthon interface"
      ],
      "metadata": {
        "id": "4H8CPqQQCaEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example dialog\n"
      ],
      "metadata": {
        "id": "mPwYsUc1Crc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: *This is an educational dialog to verify the functions developed in the previous chapters and integrated in the multi-user interface of this notebook*\n",
        "\n",
        "**Example of a multi-user session**\n",
        "\n",
        "Enter the following scenario to verify the system and then experiment to see its scope and limits.\n",
        "\n",
        "Make sure the `agent` checkbox option is checked to activate the generative AI model.\n",
        "\n",
        "Prompt 1-`user01`, to verify task orchestration for semantic analysis.\n",
        "The keyword `Pinecone` will trigger similarity search for task instructions.\n",
        "\n",
        "`A customer said that our travel agency was pretty good but should have more activities. Let's ask Pinecone for ideas. `\n",
        "\n",
        "Prompt 2-`user02` to verify task orchestration for sentiment analysis.\n",
        "The keyword `Pinecone` will trigger similarity search for task instructions.\n",
        "\n",
        "`A customer said that our travel agency was worse than our competition and should have better service. Let's ask Pinecone what its sentiment is.`\n",
        "\n",
        "Prompt 3-`user03` to verify task orchestration for RAG.   \n",
        "The keyword `RAG` will trigger similarity search for data retrieval.   \n",
        "`The CTO was talking about leveraging different kind of memories the other day. What did he mean by that? Let's search RAG.`\n",
        "\n",
        "Prompt 4-`user01`to verify task orchestration without RAG.   \n",
        "`But what you, the AI Agent, suggest we do to leverage these types of memories in are travelling promotion campaigns?`\n",
        "\n",
        "Prompt 6- `user01` unchecks the `agent` checkbox to deactivate the generative AI and just text the other users.\n",
        "\n",
        "`OK. Let's stop here, get a summary and go see the manager to get some green lights to move ahead.`"
      ],
      "metadata": {
        "id": "VQdrOoyZxblG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-vD_ytCMCifd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the interface"
      ],
      "metadata": {
        "id": "CW6YHIvZCii1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, clear_output\n",
        "from ipywidgets import Dropdown, Text, Checkbox, VBox, Layout\n",
        "import json\n",
        "\n",
        "# Initialize conversation histories for all users and active user\n",
        "user_histories = {\"User01\": [], \"User02\": [], \"User03\": []}\n",
        "active_user = \"User01\"  # Default user\n",
        "conversation_active = True\n",
        "\n",
        "# Function to handle user input and optional bot response\n",
        "def chat(user_message):\n",
        "    global conversation_active\n",
        "    # Check for exit signal\n",
        "    if user_message.lower() in ['exit', 'quit']:\n",
        "        conversation_active = False\n",
        "        clear_output(wait=True)\n",
        "        display(HTML(\"<div style='color: red;'><strong>Conversation ended. Saving history...</strong></div>\"))\n",
        "        save_conversation_history()  # Save the conversation history to a file\n",
        "        display(HTML(\"<div style='color: green;'><strong>History saved. Proceed to the next cell.</strong></div>\"))\n",
        "        return\n",
        "\n",
        "    # Append user message to the active user's history\n",
        "    user_histories[active_user].append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Generate bot response if agent_checkbox is checked\n",
        "    if agent_checkbox.value:\n",
        "        response = chat_with_gpt(user_histories[active_user], user_message)\n",
        "        # Append bot response to the active user's history\n",
        "        user_histories[active_user].append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Update display\n",
        "    update_display()\n",
        "\n",
        "# Function to update the display\n",
        "def update_display():\n",
        "    clear_output(wait=True)\n",
        "    for entry in user_histories[active_user]:  # Show only the active user's history\n",
        "        if entry['role'] == 'user':\n",
        "            display(HTML(f\"<div style='text-align: left; margin-left: 20px; color: blue;'><strong>{active_user}:</strong> {entry['content']}</div>\"))\n",
        "        elif entry['role'] == 'assistant':\n",
        "            display(HTML(f\"<div style='text-align: left; margin-left: 20px; color: green;'><strong>Agent:</strong> {entry['content']}</div>\"))\n",
        "    if conversation_active:\n",
        "        display(VBox([user_selector, input_box, agent_checkbox]))  # Keep input box, selector, and checkbox visible if active\n",
        "\n",
        "# Function to handle the submission of the input\n",
        "def handle_submit(sender):\n",
        "    user_message = sender.value\n",
        "    if user_message.strip():\n",
        "        sender.value = \"\"  # Clear the input box\n",
        "        chat(user_message)\n",
        "\n",
        "# Function to update the active user\n",
        "def on_user_change(change):\n",
        "    global active_user\n",
        "    active_user = change['new']\n",
        "    update_display()  # Update the display to show the new active user's history\n",
        "\n",
        "# Function to save conversation history to a file\n",
        "def save_conversation_history():\n",
        "    filename = \"conversation_history.json\"  # Define the filename\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(user_histories, file, indent=4)  # Write the user histories dictionary to the file in JSON format\n",
        "    display(HTML(f\"<div style='color: green;'><strong>Conversation history saved to {filename}.</strong></div>\"))\n",
        "\n",
        "# Create a dropdown to select the user\n",
        "user_selector = Dropdown(\n",
        "    options=[\"User01\", \"User02\", \"User03\"],\n",
        "    value=active_user,\n",
        "    description='User:',\n",
        "    layout=Layout(width='50%')\n",
        ")\n",
        "user_selector.observe(on_user_change, names='value')\n",
        "\n",
        "# Create the input box widget\n",
        "input_box = Text(placeholder=\"Type your message here or type 'exit' or 'quit' to end the conversation.\", layout=Layout(width='100%'))\n",
        "input_box.on_submit(handle_submit)  # Attach the on_submit event handler\n",
        "\n",
        "# Create a checkbox to toggle agent response\n",
        "agent_checkbox = Checkbox(\n",
        "    value=True,\n",
        "    description='Agent',\n",
        "    layout=Layout(width='20%')\n",
        ")\n",
        "\n",
        "# Display the initial interface\n",
        "display(VBox([user_selector, input_box, agent_checkbox], layout=Layout(display='flex', flex_flow='column', align_items='flex-start', width='100%')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "caa50029d4744f40a8d4244fd459cc79",
            "e2c87436b0654dde96b28d2905b0e0bf",
            "c5a592f0edde425aa3b0c415e763deff",
            "cde4d28a53cc496a915041411142d6da",
            "2a2f78f5d1f34df78ce50eaef72c6fca",
            "765ed4e2c99249dba075978e63f47612",
            "de0bbf6143cd45c5bd8f5baec3ef0885",
            "4c789031c7f84438ba6b6478c45c30f7",
            "2516b112d6794da19870a2358b7118ca",
            "349df2853f0148ca97e1f3682ea8d7cc",
            "660dab06c899408d8372a6f27c4febe8",
            "1528c9f73131416195e55f25a73e229a",
            "f2ca3d1f42ea4a07bb6d40290caac17b",
            "2c5c2aa6533b4fcb80a57c525233adca",
            "0077bf97b10941c2a565f48a5beeb653",
            "ac47bd5e23a340f3a777ee48a02d3c1a",
            "074b1e3e88744be484a2bb4da250284c",
            "dbae20c3402344fc93f4c2b75a86721d",
            "1ba51e1e9a074d0e89fcc1afdbe2387d",
            "ed262e19645c41ebb4626edde59ad8c9",
            "ce086e365f31482aaac7e08089e6b041"
          ]
        },
        "id": "iWtVpvQwGf_4",
        "outputId": "cad97075-a671-4931-922b-74808ef157d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='color: red;'><strong>Conversation ended. Saving history...</strong></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='color: green;'><strong>Conversation history saved to conversation_history.json.</strong></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='color: green;'><strong>History saved. Proceed to the next cell.</strong></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and display conversation"
      ],
      "metadata": {
        "id": "5hT4-GSS3Hez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# File path\n",
        "file_path = 'conversation_history.json'\n",
        "\n",
        "# Open the file and read its content into the 'dialog' variable\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    dialog = json.load(file)  # Parse JSON content\n",
        "\n",
        "# Function to format JSON content as markdown\n",
        "def format_json_as_markdown(data, level=0):\n",
        "    html_output = \"\"\n",
        "    indent = \"  \" * level\n",
        "    if isinstance(data, dict):\n",
        "        for key, value in data.items():\n",
        "            html_output += f\"{indent}**{key}**:<br>\\n\"\n",
        "            html_output += format_json_as_markdown(value, level + 1)\n",
        "    elif isinstance(data, list):\n",
        "        for item in data:\n",
        "            html_output += format_json_as_markdown(item, level)\n",
        "    else:\n",
        "        html_output += f\"{indent}{data}<br>\\n\"\n",
        "    return html_output\n",
        "\n",
        "# Format the JSON into markdown\n",
        "formatted_markdown = format_json_as_markdown(dialog)\n",
        "\n",
        "# Display formatted JSON as Markdown\n",
        "display(Markdown(formatted_markdown))"
      ],
      "metadata": {
        "id": "y8W1IpYdKyds",
        "outputId": "3523c7c4-88c2-46b9-9c30-c491c0880865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User01**:<br>\n  **role**:<br>\n    user<br>\n  **content**:<br>\n    What is the capital of France?<br>\n  **role**:<br>\n    assistant<br>\n  **content**:<br>\n    The capital of France is Paris.<br>\n  **role**:<br>\n    user<br>\n  **content**:<br>\n    What is there to visit?<br>\n  **role**:<br>\n    assistant<br>\n  **content**:<br>\n    The capital of France is Paris. There are numerous attractions to visit in Paris, including:\n\n1. **Eiffel Tower** - An iconic symbol of Paris and a must-visit landmark.\n2. **Louvre Museum** - The world's largest art museum, home to the Mona Lisa and countless other masterpieces.\n3. **Notre-Dame Cathedral** - A stunning example of French Gothic architecture.\n4. **Champs-lyses and Arc de Triomphe** - A famous avenue leading to the historic monument.\n5. **Sacr-Cur Basilica** - Located at the highest point in the city, offering panoramic views.\n6. **Montmartre** - A historic district known for its bohemian past and artistic heritage.\n7. **Palace of Versailles** - A short trip from Paris, this opulent palace is a UNESCO World Heritage site.\n8. **Seine River Cruise** - Offers a unique perspective of the city's landmarks.\n9. **Muse d'Orsay** - Houses an extensive collection of Impressionist and Post-Impressionist masterpieces.\n10. **Latin Quarter** - Known for its vibrant atmosphere, historic sites, and educational institutions.\n\nThese are just a few highlights, and Paris offers many more cultural, historical, and culinary experiences.<br>\n**User02**:<br>\n  **role**:<br>\n    user<br>\n  **content**:<br>\n    What is the capital of Spain?<br>\n  **role**:<br>\n    assistant<br>\n  **content**:<br>\n    The capital of Spain is Madrid.<br>\n  **role**:<br>\n    user<br>\n  **content**:<br>\n    What is there to visit?<br>\n  **role**:<br>\n    assistant<br>\n  **content**:<br>\n    The capital of Spain is Madrid. There are many attractions to visit in Madrid, including:\n\n1. **The Royal Palace of Madrid** - The official residence of the Spanish royal family, although it is only used for state ceremonies.\n\n2. **Prado Museum** - One of the world's premier art galleries, featuring works by Spanish masters like Velzquez and Goya.\n\n3. **Retiro Park** - A large and popular park in the city center, perfect for a leisurely stroll or a boat ride on its lake.\n\n4. **Puerta del Sol** - A bustling public square that is a central point for locals and tourists alike.\n\n5. **Plaza Mayor** - A grand square surrounded by beautiful architecture, often hosting markets and events.\n\n6. **Gran Va** - A famous street known for its vibrant atmosphere, shopping, and theaters.\n\n7. **Thyssen-Bornemisza Museum** - Another major art museum, with a diverse collection spanning various periods and styles.\n\n8. **Santiago Bernabu Stadium** - Home to Real Madrid, one of the most famous football clubs in the world.\n\n9. **Temple of Debod** - An ancient Egyptian temple that was dismantled and rebuilt in Madrid, offering a unique historical perspective.\n\n10. **Reina Sofa Museum** - A modern art museum that houses works by artists like Picasso and Dal, including Picasso's famous \"Guernica.\"\n\nThese are just a few highlights, and Madrid offers a rich cultural experience with its vibrant neighborhoods, cuisine, and nightlife.<br>\n**User03**:<br>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and summarize conversation"
      ],
      "metadata": {
        "id": "S2co30FUEhK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# File path\n",
        "file_path = 'conversation_history.json'\n",
        "\n",
        "# Open the file and read its content into the 'dialog' variable\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    dialog = file.read()\n",
        "\n",
        "# Parse the JSON content into a Python dictionary\n",
        "conversation_history_json = json.loads(dialog)\n",
        "\n",
        "# Function to construct dialog string from the JSON conversation history\n",
        "def construct_dialog_for_summary(conversation_history_json):\n",
        "    dialog = \"\"\n",
        "    for user, messages in conversation_history_json.items():\n",
        "        dialog += f\"\\n{user}:\\n\"\n",
        "        for message in messages:\n",
        "            role = message[\"role\"]\n",
        "            content = message[\"content\"]\n",
        "            dialog += f\"- {role}: {content}\\n\"\n",
        "    return dialog\n",
        "\n",
        "# Construct the full dialog from the JSON history\n",
        "formatted_dialog = construct_dialog_for_summary(conversation_history_json)\n",
        "\n",
        "# Task to summarize the conversation\n",
        "mrole = \"system\"\n",
        "mcontent = \"Your task is to read this JSON formatted text and summarize it.\"\n",
        "user_role = \"user\"\n",
        "task = f\"Read this JSON formatted text and make a very detailed summary of it with a list of actions:\\n{formatted_dialog}\"\n",
        "\n",
        "# Assuming the make_openai_api_call function is defined elsewhere\n",
        "task_response = openai_api.make_openai_api_call(task, mrole, mcontent, user_role)\n",
        "\n",
        "# Output the result\n",
        "print(task_response)"
      ],
      "metadata": {
        "id": "EEzhcMaMFYVE",
        "outputId": "37f537ec-b7bb-498b-b67f-de9c59b2479c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The JSON formatted text contains interactions between users and an assistant, where users inquire about the capitals of France and Spain and seek recommendations for attractions to visit in these cities. Below is a detailed summary with a list of actions:\n",
            "\n",
            "### User01 Interaction:\n",
            "1. **Question about the Capital of France:**\n",
            "   - User01 asks for the capital of France.\n",
            "   - The assistant responds that the capital of France is Paris.\n",
            "\n",
            "2. **Inquiry about Attractions in Paris:**\n",
            "   - User01 asks what there is to visit in Paris.\n",
            "   - The assistant provides a list of notable attractions in Paris:\n",
            "     1. **Eiffel Tower** - Iconic symbol and must-visit landmark.\n",
            "     2. **Louvre Museum** - Largest art museum, home to the Mona Lisa.\n",
            "     3. **Notre-Dame Cathedral** - Example of French Gothic architecture.\n",
            "     4. **Champs-lyses and Arc de Triomphe** - Famous avenue and historic monument.\n",
            "     5. **Sacr-Cur Basilica** - Offers panoramic views from the highest point in the city.\n",
            "     6. **Montmartre** - Known for its bohemian past and artistic heritage.\n",
            "     7. **Palace of Versailles** - Opulent palace and UNESCO World Heritage site.\n",
            "     8. **Seine River Cruise** - Offers unique city landmark views.\n",
            "     9. **Muse d'Orsay** - Extensive collection of Impressionist and Post-Impressionist art.\n",
            "     10. **Latin Quarter** - Vibrant atmosphere with historic sites and educational institutions.\n",
            "   - The assistant notes that these are just highlights and that Paris offers many more cultural, historical, and culinary experiences.\n",
            "\n",
            "### User02 Interaction:\n",
            "1. **Question about the Capital of Spain:**\n",
            "   - User02 asks for the capital of Spain.\n",
            "   - The assistant responds that the capital of Spain is Madrid.\n",
            "\n",
            "2. **Inquiry about Attractions in Madrid:**\n",
            "   - User02 asks what there is to visit in Madrid.\n",
            "   - The assistant provides a list of notable attractions in Madrid:\n",
            "     1. **The Royal Palace of Madrid** - Official residence for state ceremonies.\n",
            "     2. **Prado Museum** - Premier art gallery with works by Velzquez and Goya.\n",
            "     3. **Retiro Park** - Popular park for strolls and boat rides.\n",
            "     4. **Puerta del Sol** - Central public square for locals and tourists.\n",
            "     5. **Plaza Mayor** - Grand square with beautiful architecture.\n",
            "     6. **Gran Va** - Famous street for shopping and theaters.\n",
            "     7. **Thyssen-Bornemisza Museum** - Art museum with diverse collections.\n",
            "     8. **Santiago Bernabu Stadium** - Home to Real Madrid football club.\n",
            "     9. **Temple of Debod** - Ancient Egyptian temple rebuilt in Madrid.\n",
            "     10. **Reina Sofa Museum** - Modern art museum with works by Picasso and Dal.\n",
            "   - The assistant notes that these are just highlights and that Madrid offers a rich cultural experience with vibrant neighborhoods, cuisine, and nightlife.\n",
            "\n",
            "### Actions:\n",
            "- User01 and User02 both inquire about the capitals of France and Spain, respectively.\n",
            "- Both users request information on attractions in Paris and Madrid.\n",
            "- The assistant provides detailed lists of attractions for both cities, highlighting cultural, historical, and artistic sites.\n",
            "- The assistant emphasizes that the lists are highlights and that both cities offer additional experiences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "# Display the task response as Markdown\n",
        "display(Markdown(task_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "-c_DUElFFehV",
        "outputId": "1408b36e-0734-45e3-fb54-1efac0ca8c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The JSON formatted text contains interactions between users and an assistant, where users inquire about the capitals of France and Spain and seek recommendations for attractions to visit in these cities. Below is a detailed summary with a list of actions:\n\n### User01 Interaction:\n1. **Question about the Capital of France:**\n   - User01 asks for the capital of France.\n   - The assistant responds that the capital of France is Paris.\n\n2. **Inquiry about Attractions in Paris:**\n   - User01 asks what there is to visit in Paris.\n   - The assistant provides a list of notable attractions in Paris:\n     1. **Eiffel Tower** - Iconic symbol and must-visit landmark.\n     2. **Louvre Museum** - Largest art museum, home to the Mona Lisa.\n     3. **Notre-Dame Cathedral** - Example of French Gothic architecture.\n     4. **Champs-lyses and Arc de Triomphe** - Famous avenue and historic monument.\n     5. **Sacr-Cur Basilica** - Offers panoramic views from the highest point in the city.\n     6. **Montmartre** - Known for its bohemian past and artistic heritage.\n     7. **Palace of Versailles** - Opulent palace and UNESCO World Heritage site.\n     8. **Seine River Cruise** - Offers unique city landmark views.\n     9. **Muse d'Orsay** - Extensive collection of Impressionist and Post-Impressionist art.\n     10. **Latin Quarter** - Vibrant atmosphere with historic sites and educational institutions.\n   - The assistant notes that these are just highlights and that Paris offers many more cultural, historical, and culinary experiences.\n\n### User02 Interaction:\n1. **Question about the Capital of Spain:**\n   - User02 asks for the capital of Spain.\n   - The assistant responds that the capital of Spain is Madrid.\n\n2. **Inquiry about Attractions in Madrid:**\n   - User02 asks what there is to visit in Madrid.\n   - The assistant provides a list of notable attractions in Madrid:\n     1. **The Royal Palace of Madrid** - Official residence for state ceremonies.\n     2. **Prado Museum** - Premier art gallery with works by Velzquez and Goya.\n     3. **Retiro Park** - Popular park for strolls and boat rides.\n     4. **Puerta del Sol** - Central public square for locals and tourists.\n     5. **Plaza Mayor** - Grand square with beautiful architecture.\n     6. **Gran Va** - Famous street for shopping and theaters.\n     7. **Thyssen-Bornemisza Museum** - Art museum with diverse collections.\n     8. **Santiago Bernabu Stadium** - Home to Real Madrid football club.\n     9. **Temple of Debod** - Ancient Egyptian temple rebuilt in Madrid.\n     10. **Reina Sofa Museum** - Modern art museum with works by Picasso and Dal.\n   - The assistant notes that these are just highlights and that Madrid offers a rich cultural experience with vibrant neighborhoods, cuisine, and nightlife.\n\n### Actions:\n- User01 and User02 both inquire about the capitals of France and Spain, respectively.\n- Both users request information on attractions in Paris and Madrid.\n- The assistant provides detailed lists of attractions for both cities, highlighting cultural, historical, and artistic sites.\n- The assistant emphasizes that the lists are highlights and that both cities offer additional experiences."
          },
          "metadata": {}
        }
      ]
    }
  ]
}