{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis2054/Building-Business-Ready-Generative-AI-Systems/blob/main/Chapter10/GenAISYS_%26_MAS_No_Interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Orchestrating AI Agents: A Strategic Framework from Controlled Systems to Swarm MAS(Multi-Agent System) Intelligence\n",
        "\n",
        "Copyright 2025, Denis Rothman\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fV0UYJjiYF2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environement of the multi-agent simulation"
      ],
      "metadata": {
        "id": "yGVOYBDhm4ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The OpenAI \"brain\"\n",
        "The program uses OpenAI's LLMs as the core \"brain\" to perform the actual work of solving each NLP task and summarizing the final results."
      ],
      "metadata": {
        "id": "xG2c0gzZR29R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvpvOPbV_ZB2",
        "outputId": "b99daf44-de57-4d91-aee1-091661c680e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "api_key=f.readline()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Asynchronous Toolkit: running agent-workers concurrently\n",
        "\n",
        "`asyncio `is Python's library for *concurrency*. It lets other agents run while some are waiting for network responses.\n",
        "\n",
        "`aiohttp`, an async HTTP client, will be used to call the OpenAI API. It works with `asyncio` so that other agents will run while an agent is waiting for a network response.\n",
        "\n",
        "`nest_asyncio` is a patch for asyncio to work in Jupyter notebooks that have an active event loop to manage a session. It is not needed for scripts on a server, which create their own event loop."
      ],
      "metadata": {
        "id": "rOjwSHo6S-Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio # part of the Python library\n",
        "import aiohttp # third party library"
      ],
      "metadata": {
        "id": "HNqqT7fql6vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installs nest_asyncio\n",
        "try:\n",
        "  import nest_asyncio\n",
        "  nest_asyncio.apply()\n",
        "except ImportError:\n",
        "  print(\"Installing nest_asyncio...\")\n",
        "  import subprocess\n",
        "  import sys\n",
        "  subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio==1.6.0\"])\n",
        "  import nest_asyncio\n",
        "  nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Ho9ix-sUW3X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent task acquisition\n",
        "\n",
        "Tasks can be provided from any source"
      ],
      "metadata": {
        "id": "h2Upv2kNnAlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "def agent_task_aquisition(filename=\"tasks.txt\"):\n",
        "  !curl -L -H \"Authorization: Bearer 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\" https://raw.githubusercontent.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/master/Chapter10/{filename} --output \"{filename}\"\n",
        "  try:\n",
        "    df = pd.read_csv(filename, header=None, on_bad_lines='skip', names=['Tasks'])\n",
        "    print(f\"Successfully loaded {len(df)} tasks from {filename}\")\n",
        "    tasks = df['Tasks'].dropna().tolist()\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading tasks: {e}\")\n",
        "  return tasks"
      ],
      "metadata": {
        "id": "4FlRhoAgkbE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The worker agents and the orchestrator\n",
        "\n",
        "In a multi-agent system, we have individual \"agents\" that perform tasks and are managed by an \"orchestrator\" (or \"controller\").\n",
        "\n",
        "In this example, we have:\n",
        "* a **worker agent** that peforms a task\n",
        "* a **summarizer agent** that can summarize tasks\n",
        "* an **orchestrator** that manages the agents"
      ],
      "metadata": {
        "id": "GC8Jnm-BpGxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Worker agent"
      ],
      "metadata": {
        "id": "FE-k5u-QoU2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Worker Agent ---\n",
        "# This agent's job is to take a single task (a prompt), send it to the\n",
        "# OpenAI API, and return the result. It's an independent specialist.\n",
        "\n",
        "async def worker_agent(session, task, api_key, model_name=\"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Represents a single, autonomous agent that performs a task.\n",
        "    It takes a task description and returns the API response.\n",
        "    \"\"\"\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    # The payload contains the prompt engineering for the agent.\n",
        "    # \"system\" sets the AI's persona and overall instructions.\n",
        "    # \"assistant\" provides an example of the desired output format.\n",
        "    # \"user\" inserts the specific task for this agent instance.\n",
        "    payload = {\n",
        "        \"model\": model_name,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1. You can explain any NLP task. 2. Create an example. 3. Solve the example.\"},\n",
        "            {\"role\": \"user\", \"content\": task}\n",
        "        ],\n",
        "        \"temperature\": 0.1\n",
        "    }\n",
        "\n",
        "    # print(f\"Worker Agent dispatched for task: '{task[:50]}...'\")\n",
        "    try:\n",
        "        async with session.post(url, json=payload, headers=headers) as response:\n",
        "            response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
        "            if response.headers.get('Content-Type') == 'application/json':\n",
        "                return await response.json()\n",
        "            else:\n",
        "                text = await response.text()\n",
        "                print(f\"Error: Unexpected response content type: {response.headers.get('Content-Type')}\")\n",
        "                return {\"error\": text}\n",
        "    except aiohttp.ClientError as e:\n",
        "        print(f\"An HTTP error occurred: {e}\")\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "L2xFOM2imIeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizer Agent"
      ],
      "metadata": {
        "id": "6Cbyx0y7ogYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- \"Summarizer Agent\" ---\n",
        "# This agent takes the results from all the worker agents and creates a summary.\n",
        "# This demonstrates an agent that relies on the output of other agents.\n",
        "\n",
        "async def summarizer_agent(session, completed_tasks, api_key, model_name=\"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    An agent that synthesizes results from other agents into a summary.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Summarizer Agent Activated ---\")\n",
        "    print(\"Task: To summarize the findings from the worker swarm.\")\n",
        "\n",
        "    # Note: We are using the full list of completed tasks for the summary.\n",
        "    # For cost or speed, this could be parameterized to send only a sample,\n",
        "    # for example: .join(completed_tasks[:sample_size])\n",
        "    summary_input = \"\\n\\n---\\n\\n\".join(completed_tasks)\n",
        "\n",
        "    # This prompt is engineered to ask for a high-level overview\n",
        "    # rather than a detailed analysis of every single task.\n",
        "    prompt = f\"\"\"\n",
        "    The following are the results from several NLP task evaluations.\n",
        "    Please provide a brief, high-level summary of the topics covered.\n",
        "    Do not analyze every single task, but give a general overview of the types of problems solved.\n",
        "\n",
        "    REPORTS:\n",
        "    ---\n",
        "    {summary_input}\n",
        "    ---\n",
        "    END OF REPORTS.\n",
        "\n",
        "    Your summary:\n",
        "    \"\"\"\n",
        "\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model_name,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert AI analyst tasked with summarizing agent outputs.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        # A higher temperature (e.g., 0.5) is used here to allow for more creative and fluent summarization.\n",
        "        \"temperature\": 0.5\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with session.post(url, json=payload, headers=headers) as response:\n",
        "            response.raise_for_status()\n",
        "            if response.headers.get('Content-Type') == 'application/json':\n",
        "                return await response.json()\n",
        "            else:\n",
        "                text = await response.text()\n",
        "                print(f\"Summarizer Error: Unexpected response content type: {response.headers.get('Content-Type')}\")\n",
        "                return {\"error\": text}\n",
        "    except aiohttp.ClientError as e:\n",
        "        print(f\"An HTTP error occurred in summarizer: {e}\")\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "8PDMfn6Kod5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orchestrator Definition"
      ],
      "metadata": {
        "id": "_M-l64L-nkbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"Swarm Orchestrator\" now manages a two-stage process.\n",
        "#  1. A swarm of worker agents to process a list of tasks concurrently\n",
        "#  2. A summarizer agent to process the collected results.\n",
        "async def swarm_orchestrator(tasks, api_key, model_name=\"gpt-4o-mini\"):\n",
        "    print(f\"\\n--- Orchestrator starting: Managing a swarm of {len(tasks)} agents for model {model_name} ---\")\n",
        "    all_results = []\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        # --- STAGE 1: Worker Agent Swarm ---\n",
        "        print(\"\\n--- STAGE 1: Dispatching Worker Swarm ---\")\n",
        "        worker_coroutines = [worker_agent(session, task, api_key, model_name) for task in tasks]\n",
        "        worker_responses = await asyncio.gather(*worker_coroutines, return_exceptions=True)\n",
        "        print(\"\\n--- All worker agents have completed their tasks. Processing results. ---\")\n",
        "\n",
        "        for i, response in enumerate(worker_responses):\n",
        "            task_num = i + 1\n",
        "            input_text = tasks[i]\n",
        "            if isinstance(response, Exception):\n",
        "                print(f\"Task {task_num} failed with an exception: {response}\")\n",
        "                continue\n",
        "\n",
        "            if response and 'choices' in response and response['choices']:\n",
        "                content = response['choices'][0]['message']['content']\n",
        "                all_results.append(f\"Task {task_num}: {content}\") # Collect results for summarizer\n",
        "                try:\n",
        "                    parts = input_text.split('Solve it:')\n",
        "                    bb_task = parts[1].strip()\n",
        "                    display_response(task_num, input_text, content.replace('\\n', '<br>'), bb_task)\n",
        "                except IndexError:\n",
        "                    display_response(task_num, input_text, content.replace('\\n', '<br>'), \"Task Description Unavailable\")\n",
        "            else:\n",
        "                print(f\"Error in response for task {task_num}: {input_text}, Response: {response.get('error', response)}\")\n",
        "\n",
        "        # --- STAGE 2: Summarizer Agent ---\n",
        "        print(\"\\n--- STAGE 2: Dispatching Summarizer Agent ---\")\n",
        "        if all_results:\n",
        "            summary_response = await summarizer_agent(session, all_results, api_key, model_name)\n",
        "            if summary_response and 'choices' in summary_response and summary_response['choices']:\n",
        "                summary_content = summary_response['choices'][0]['message']['content']\n",
        "                display_summary(summary_content)\n",
        "            else:\n",
        "                 print(f\"Could not generate summary. Response: {summary_response.get('error', summary_response)}\")\n",
        "        else:\n",
        "            print(\"No results to summarize.\")\n"
      ],
      "metadata": {
        "id": "aNzH8iZmmQZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "zVd2tZ4knqhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Functions ---\n",
        "from IPython.display import display, HTML\n",
        "def display_response(task_num, input_text, formatted_task, bb_task):\n",
        "    \"\"\"\n",
        "    A simple display function to present the results from a worker agent.\n",
        "    \"\"\"\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "      <head>\n",
        "        <style>\n",
        "            body {{ font-family: sans-serif; margin: 1em; }}\n",
        "            h1 {{ font-size: 1.2em; color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px;}}\n",
        "            p {{ line-height: 1.6; color: #34495e; font-size: 0.9em; }}\n",
        "            .task-card {{ background-color: #f9f9f9; border: 1px solid #ddd; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 20px; border-radius: 5px; }}\n",
        "        </style>\n",
        "      </head>\n",
        "      <body>\n",
        "        <div class=\"task-card\">\n",
        "          <h1>Worker Agent Result for Task {task_num}: {bb_task}</h1>\n",
        "          <p>{formatted_task}</p>\n",
        "        </div>\n",
        "      </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    display(HTML(html_content))\n",
        "\n",
        "def display_summary(summary_content):\n",
        "    \"\"\"\n",
        "    A new display function for the final summary.\n",
        "    \"\"\"\n",
        "    formatted_summary = summary_content.replace('\\n', '<br>')\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "      <head>\n",
        "        <style>\n",
        "            body {{ font-family: sans-serif; margin: 1em; }}\n",
        "            h1 {{ font-size: 1.3em; color: #27ae60; border-bottom: 2px solid #2ecc71; padding-bottom: 5px;}}\n",
        "            p {{ line-height: 1.6; color: #34495e; }}\n",
        "            .summary-card {{ background-color: #e8f8f5; border: 1px solid #a3e4d7; border-left: 5px solid #2ecc71; padding: 15px; margin-top: 20px; border-radius: 5px; }}\n",
        "        </style>\n",
        "      </head>\n",
        "      <body>\n",
        "        <div class=\"summary-card\">\n",
        "          <h1>Orchestrator's Final Summary</h1>\n",
        "          <p>{formatted_summary}</p>\n",
        "        </div>\n",
        "      </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    display(HTML(html_content))\n"
      ],
      "metadata": {
        "id": "0NrzAdLbmVsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The main multi-agent simulation block"
      ],
      "metadata": {
        "id": "qWxh4o6cn6EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Execution Block ---\n",
        "import time\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the multi-agent simulation.\n",
        "    \"\"\"\n",
        "    print(\"Loading the tasks from any source...\")\n",
        "    tasks=agent_task_aquisition(filename=\"tasks.txt\")\n",
        "    if not tasks:\n",
        "        print(\"âŒ No tasks to process. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # --- Select Model and Run ---\n",
        "    selected_model = \"gpt-4o-mini\"\n",
        "    print(f\"\\nSelected Model: {selected_model}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # CORRECTED: The call to the orchestrator was not waiting for completion.\n",
        "    # A simple `asyncio.run()` call works correctly in both standard\n",
        "    # Python and notebook environments (thanks to nest_asyncio) and ensures\n",
        "    # the program waits for all async tasks to finish.\n",
        "    asyncio.run(swarm_orchestrator(tasks, API_KEY, selected_model))\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    num_tasks = len(tasks)\n",
        "    avg_time_per_task = total_time / num_tasks if num_tasks > 0 else 0\n",
        "\n",
        "    # standard print calls\n",
        "    # to prevent syntax errors in all environments.\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SWARM PROCESSING COMPLETE\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total Response Time: {total_time:.2f} seconds\")\n",
        "    print(f\"Total Tasks Processed: {num_tasks}\")\n",
        "    print(f\"Average time per task: {avg_time_per_task:.4f} seconds\")\n",
        "    print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "Q55nmTsNmmbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To run in a Colab/Jupyter notebook, `main()`is in a cell and runs the program\n",
        "# If running as a standard .py file, the following block executes.\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "V_7rKKwJPkqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}